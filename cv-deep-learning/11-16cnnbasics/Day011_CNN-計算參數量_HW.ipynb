{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6jN0Y8x4gNA"
   },
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用Keras搭建簡單的Dense Layer與 Convolution2D Layer，使用相同Neurons數量，計算總參數量相差多少。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 本次練習主要是要讓各位同學們了解CNN與FC層的參數使用量差異\n",
    "  #### Convolution2D有許多參數可以設置，之後章節會細談\n",
    "  #### 不熟Keras的學員們也可以藉此了解NN層的不同搭法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAFr7hM24gNB"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 288)               226080    \n",
      "=================================================================\n",
      "Total params: 226,080\n",
      "Trainable params: 226,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'理解輸出Total params為何==226080'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##輸入照片尺寸==28*28*1\n",
    "##都用一層，288個神經元\n",
    "\n",
    "##建造一個一層的CNN層\n",
    "classifier=Sequential()\n",
    "\n",
    "##Kernel size 3*3，用32張，輸入大小28*28*1\n",
    "classifier.add(Convolution2D(filters = 32, kernel_size=(3,3), #(3*3*1+1)32=320\n",
    "            input_shape=(28, 28,1)))\n",
    "'''32張Kernel，大小為3*3，輸入尺寸為28*28*1'''\n",
    "##看看model結構\n",
    "print(classifier.summary())\n",
    "'''理解輸出Total params為何==320'''\n",
    "\n",
    "##建造一個一層的FC層\n",
    "classifier=Sequential()\n",
    "##輸入為28*28*1攤平==784\n",
    "inputs = Input(shape=(784,))\n",
    "'''輸入尺寸為28*28*1'''\n",
    "##CNN中用了(3*3*1)*32個神經元，我們這邊也用相同神經元數量\n",
    "x=Dense(288)(inputs) #784*288+288=226080\n",
    "'''使用288個神經元'''\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "##看看model結構\n",
    "print(model.summary())\n",
    "\n",
    "'''理解輸出Total params為何==226080'''\n",
    "\n",
    "##大家可以自己變換設定看看參數變化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "\n",
    "what's convolution?\n",
    "\n",
    "「透過卷積核 (Kernels) 滑動對圖像做訊息提取，並藉由步長 (Strides) 與填充 (Padding) 控制圖像的長寬。」\n",
    "\n",
    "## kernels\n",
    "\n",
    "- 又稱為 Filter、Kernel、feature detector\n",
    "- 卷積核大小(kernel_size)：自定義，常見大小如 3\\*3、5\\*5。\n",
    "- 用途： Kernel 用來學習圖像的特徵，Kernel 的張數 (filters) 決定學習的參數量，Kernel 大小決定 Kernels 的特徵接受域 (Receptive field)，也就是看到特徵的大小。\n",
    "\n",
    "- 起始值：一個 3\\*3的 Kernel，其中的值就是我們要訓練的權重，通常用常態分佈隨機產生，再經由訓練更新。\n",
    "- 張數：控制張數主要就是控制學習的參數量，常見是16、32 或 64，如果使用16張 Kernels 就能達到很好的效果，也就不需要浪費額外的參數去增加學習與計算量。\n",
    "- Kernel 大小影響 ：Kernel 大小與其 Receptive field 有關，Receptive field 直觀來說就是 Kernel 提取資訊的尺度，現在普遍流行的方式是選用不同大小的 Kernel 對圖像做卷積後，再把輸出的 Feature maps 合併或平均。 \n",
    "\n",
    "(奇數Kernel有幾個先天上的優勢，第一個原因是由於基數的卷積核有中心點，較容易對齊確認位置資訊，再者是因為奇數的卷積核能確保Padding的對稱性。)\n",
    "\n",
    "## CNN 的重點與優勢\n",
    "\n",
    "### 權值共享\n",
    "\n",
    "在一般的圖像內有許多的特徵是相同的，如特定的輪廓或線條，因此可以使用相同幾個神經元組成的卷積核去學這個特徵，透過滑動窗口對整張圖片進行卷積，進而達到節省參數的效果。\n",
    "\n",
    "### CNN and FC\n",
    "\n",
    "fc: flatten, input\\*output+output, 保留語意訊息\n",
    "\n",
    "cnn: convolution, (kh\\*kw\\*channel+1)kernelnumber, 保留空間訊息\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNN-計算參數量.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
