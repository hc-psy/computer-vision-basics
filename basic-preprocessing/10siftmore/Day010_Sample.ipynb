{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徵應用\n",
    "當我們取得特徵之後，就代表我們已經有能力去識別關鍵點的特殊性\n",
    "\n",
    "在這之後可以接到許多電腦視覺的任務\n",
    "- 配對：判斷兩張圖片上相同物體的位置\n",
    "- 辨識：判斷兩張圖片上是否有相同物體\n",
    "- 全景圖：尋找兩張圖片的相同視角，再經過轉換合成全景圖\n",
    "- ...\n",
    "廣泛的說，SIFT 只是其中一種抽取特徵的方式，這邊會延續上一章節以 SIFT 為例介紹配對的應用。\n",
    "\n",
    "### Feature Matching\n",
    "\n",
    "配對會從兩張圖片中的關鍵點中，透過計算其特徵空間上的距離，若小於一個設定的閥值就視為是相同的特徵\n",
    "\n",
    "在 SIFT 特徵的配對任務中，通常會使用 L2 norm 的方式計算。兩個 128 維向量(敘述子)可以得到一個距離\n",
    "\n",
    "actually it's similiarity\n",
    "\n",
    "簡單暴力的配對方法是逐一針對 query image 的關鍵點\n",
    "\n",
    "對每個 train image 的關鍵點計算 L2 距離\n",
    "\n",
    "- 取得距離最小的配對\n",
    "- 取得 k 個最適合的配對(針對每個query都找k個適合的)\n",
    "\n",
    "這邊為了確保配對的合適性，可以先在計算時取得 k 個配對，在根據距離(ratio test)去過濾不適合的配對\n",
    "\n",
    "#### ratio test\n",
    "\n",
    "我們可以尋找 k=2 個最好的 match 方式，透過 ratio test 的方式來過濾一些不適當的配對，因為有時候 query 的關鍵點並不會出現在 train image( 0.7~0.8 is suggested)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 範例\n",
    "\n",
    "透過 SIFT 特徵實作 Brute-Force Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 以灰階方式讀入圖片\n",
    "img_query = cv2.imread('box.png', 0)\n",
    "img_train = cv2.imread('box_in_scene.png', 0)\n",
    "\n",
    "# 建立 SIFT 物件\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# 偵測並計算 SIFT 特徵 (keypoints 關鍵點, descriptor 128 維敘述子)\n",
    "kp_query, des_query = sift.detectAndCompute(img_query, None) #None是mask參數 可以針對部分圖片做處理\n",
    "kp_train, des_train = sift.detectAndCompute(img_train, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基於 SIFT 特徵的暴力比對\n",
    "\n",
    "- D.Lowe ratio test\n",
    "- knn 比對"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 Brute-Force Matching 物件\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "\n",
    "# 以 knn 方式暴力比對特徵\n",
    "matches = bf.knnMatch(des_query, des_train, k=2)\n",
    "\n",
    "# 透過 D.Lowe ratio test 排除不適合的配對\n",
    "candidate = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.75*n.distance: #m is closest and n is next closest\n",
    "        candidate.append([m])\n",
    "\n",
    "# 顯示配對結果\n",
    "img_show = cv2.drawMatchesKnn(img_query, kp_query, img_train, kp_train, candidate, None, flags=2) #flag=2沒有配對成功不會被標記\n",
    "\n",
    "# 顯示圖片\n",
    "while True:\n",
    "    cv2.imshow('matches', img_show)\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### related to ML\n",
    "\n",
    "SIFT 可以抽取特徵，ML也可以抽取特徵\n",
    "\n",
    "SIFT抽取完後做ML，注意維度問題(每張圖片特徵點數量不同)\n",
    "\n",
    "其中一種作法是做 Clustering，每一張圖片都取 n 個特徵點來固定圖片的特徵維度\n",
    "\n",
    "缺點：\n",
    "\n",
    "如果圖片太簡單導致部份圖片特徵太少就會失效，所以類似 MNIST 或是 CIFAR 等簡單的資料集就不太適合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
